{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63V9uWTSrZeh"
      },
      "source": [
        "# **Question 13**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkwPS1NUrPXt",
        "outputId": "6f8e4147-b1ef-42e6-810e-df5fc0ca7e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports required in this project\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.metrics import ndcg_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import ndcg_score\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "nF6kr6Ee-_R6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twoBbK3VfY4M",
        "outputId": "4ac2c5ef-3270-4fda-a020-34e074547793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mounting the drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset for one fold\n",
        "def load_one_fold(data_path):\n",
        "    X_train, y_train, qid_train = load_svmlight_file(str(data_path + 'train.txt'), query_id=True)\n",
        "    X_test, y_test, qid_test = load_svmlight_file(str(data_path + 'test.txt'), query_id=True)\n",
        "    y_train = y_train.astype(int)\n",
        "    y_test = y_test.astype(int)\n",
        "    _, group_train = np.unique(qid_train, return_counts=True)\n",
        "    _, group_test = np.unique(qid_test, return_counts=True)\n",
        "    return X_train, y_train, qid_train, group_train, X_test, y_test, qid_test, group_test\n",
        "\n",
        "def ndcg_single_query(y_score, y_true, k):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "\n",
        "    gain = 2 ** y_true - 1\n",
        "\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gain / discounts)\n",
        "\n",
        "# calculate NDCG score given a trained model\n",
        "def compute_ndcg_all(model, X_test, y_test, qids_test, k=10):\n",
        "    unique_qids = np.unique(qids_test)\n",
        "    ndcg_ = list()\n",
        "    for i, qid in enumerate(unique_qids):\n",
        "        y = y_test[qids_test == qid]\n",
        "\n",
        "        if np.sum(y) == 0:\n",
        "            continue\n",
        "\n",
        "        p = model.predict(X_test[qids_test == qid])\n",
        "\n",
        "        idcg = ndcg_single_query(y, y, k=k)\n",
        "        ndcg_.append(ndcg_single_query(p, y, k=k) / idcg)\n",
        "    return np.mean(ndcg_)\n",
        "\n",
        "# get importance of features\n",
        "def get_feature_importance(model, importance_type='gain'):\n",
        "    return model.feature_importance(importance_type=importance_type)"
      ],
      "metadata": {
        "id": "onLWAy_b_Lkz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1vr_Ws61fsu-"
      },
      "outputs": [],
      "source": [
        "#Giving the path to the wek10k folder\n",
        "web10k_path='gdrive/My Drive/Winter Quarter 2024/219 - Large Scale Data Mining/Project 3/MSLR-WEB10K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SCXZy9jai7GY"
      },
      "outputs": [],
      "source": [
        "#Loading all the data from the folders\n",
        "X_train_fold1, y_train_fold1, qid_train_fold1, group_train_fold1, X_test_fold1, y_test_fold1, qid_test_fold1, group_test_fold1 = load_one_fold(web10k_path+'/Fold1/')\n",
        "X_train_fold2, y_train_fold2, qid_train_fold2, group_train_fold2, X_test_fold2, y_test_fold2, qid_test_fold2, group_test_fold2 = load_one_fold(web10k_path+'/Fold2/')\n",
        "X_train_fold3, y_train_fold3, qid_train_fold3, group_train_fold3, X_test_fold3, y_test_fold3, qid_test_fold3, group_test_fold3 = load_one_fold(web10k_path+'/Fold3/')\n",
        "X_train_fold4, y_train_fold4, qid_train_fold4, group_train_fold4, X_test_fold4, y_test_fold4, qid_test_fold4, group_test_fold4 = load_one_fold(web10k_path+'/Fold4/')\n",
        "X_train_fold5, y_train_fold5, qid_train_fold5, group_train_fold5, X_test_fold5, y_test_fold5, qid_test_fold5, group_test_fold5 = load_one_fold(web10k_path+'/Fold5/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv-D7Q4KjEqT",
        "outputId": "595fb1f8-9863-4bf8-a15f-a77a4e8a3f5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<723412x136 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 98384032 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train_fold1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining all the qid_train of all the folders\n",
        "qid_train= np.concatenate((qid_train_fold1, qid_train_fold2, qid_train_fold3, qid_train_fold4, qid_train_fold5))\n",
        "print(qid_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KcdHbAdT0YC",
        "outputId": "9a6ea001-559b-4bb2-998a-62ea01c4147c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3600576,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining all the qid_test of all the folders\n",
        "qid_test = np.concatenate((qid_test_fold1, qid_test_fold2, qid_test_fold3, qid_test_fold4, qid_test_fold5))\n",
        "print(qid_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQCNo9PbUB_Y",
        "outputId": "796c6da9-1176-46bc-ea74-be451b49fbd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200192,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining all the y_train of all the folders\n",
        "y_train = np.concatenate((y_train_fold1, y_train_fold2, y_train_fold3, y_train_fold4, y_train_fold5))\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyA0WbWCVigS",
        "outputId": "9c213ccf-8285-4152-e47b-58a4a5d0cee0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3600576,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining all the y_test of all the folders\n",
        "y_test = np.concatenate((y_test_fold1, y_test_fold2, y_test_fold3, y_test_fold4, y_test_fold5))\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIpvHLdZVkjE",
        "outputId": "ae651ac9-c3f0-4f59-a8ba-19c176aac9c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200192,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_fold1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Zkl8FbWHTL",
        "outputId": "6d39e6c1-cb2f-4b85-e529-60220ccfee1e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(723412, 136)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_fold2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_lYo3VpWTTi",
        "outputId": "218fa47c-6007-4d42-9093-7d2571a2de4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(716683, 136)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the number of unique queries in the training and testing set\n",
        "unique_queries_train = len(np.unique(qid_train))\n",
        "unique_queries_test = len(np.unique(qid_test))\n",
        "\n",
        "print(\"The number of unique queries in training set is\", unique_queries_train)\n",
        "print(\"The number of unique queries in testing set is\", unique_queries_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2lRXdV4Wpe0",
        "outputId": "618abf76-8043-46cd-daff-e7ef7d33837d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of unique queries in training set is 10000\n",
            "The number of unique queries in testing set is 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a bar graph of the relevance labels and its frequency in the train data\n",
        "unique_relevance_train, no_of_train = np.unique(y_train, return_counts=True)\n",
        "\n",
        "plt.bar(unique_relevance_train, no_of_train)\n",
        "plt.title(\"Distribution of Relevance Labels in Train\")\n",
        "plt.xlabel(\"Relevance Labels\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "w0xdzm6jW2Cq",
        "outputId": "98899b6a-1ad7-411e-8b4c-4b6709a99922"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a bar graph of the relevance labels and its frequency in the test data\n",
        "unique_relevance_test, no_of_test = np.unique(y_test, return_counts=True)\n",
        "plt.bar(unique_relevance_test, no_of_test)\n",
        "plt.title(\"Distribution of Relevance Labels in Test\")\n",
        "plt.xlabel(\"Relevance Labels\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DJoHqErpW4qA",
        "outputId": "992c057b-1dbb-47b4-8d87-a8febe1cc811"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 13:\n",
        "Data Understanding and Preprocessing:\n",
        "Use the provided helper code for loading and pre-processing Web10k data.\n",
        "Print out the number of unique queries in total and show distribution of relevance labels.\n",
        "\n",
        ">The number of unique queries in training set is 10000\\\n",
        "The number of unique queries in testing set is 10000\\\n",
        "Refer to the bar graphs above to see the distribution of relevance labels.\n"
      ],
      "metadata": {
        "id": "x87Y1u_UG8br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 14**"
      ],
      "metadata": {
        "id": "tRwNMMVDXW8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[\n",
        "    (X_train_fold1, y_train_fold1, qid_train_fold1, group_train_fold1, X_test_fold1, y_test_fold1, qid_test_fold1, group_test_fold1),\n",
        "    (X_train_fold2, y_train_fold2, qid_train_fold2, group_train_fold2, X_test_fold2, y_test_fold2, qid_test_fold2, group_test_fold2),\n",
        "    (X_train_fold3, y_train_fold3, qid_train_fold3, group_train_fold3, X_test_fold3, y_test_fold3, qid_test_fold3, group_test_fold3),\n",
        "    (X_train_fold4, y_train_fold4, qid_train_fold4, group_train_fold4, X_test_fold4, y_test_fold4, qid_test_fold4, group_test_fold4),\n",
        "    (X_train_fold5, y_train_fold5, qid_train_fold5, group_train_fold5, X_test_fold5, y_test_fold5, qid_test_fold5, group_test_fold5)\n",
        "]"
      ],
      "metadata": {
        "id": "gSFvgV7qO3Oz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LightGBM parameters\n",
        "params = {\n",
        "    'objective': 'lambdarank',\n",
        "    # Can add other parameters such as learning rate, max_depth, etc.\n",
        "}"
      ],
      "metadata": {
        "id": "Sko4pKlzO6Ua"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndcg_values=[]\n",
        "\n",
        "# Iterate over each fold\n",
        "for fold, (X_train, y_train, qid_train, group_train, X_test, y_test, qid_test, group_test) in enumerate(data):\n",
        "\n",
        "    # Create a LightGBM dataset for training\n",
        "    train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
        "\n",
        "    # Train the LightGBM model\n",
        "    gbm = lgb.train(params, train_data)\n",
        "\n",
        "    # Evaluate the predictions using nDCG@3, nDCG@5, and nDCG@10\n",
        "    ndcg_3 = compute_ndcg_all(gbm,X_test, y_test, qid_test, k=3)\n",
        "    ndcg_5 = compute_ndcg_all(gbm,X_test, y_test, qid_test, k=5)\n",
        "    ndcg_10 = compute_ndcg_all(gmb,X_test, y_test, qid_test, k=10)\n",
        "\n",
        "    ndcg_values.append([ndcg_3, ndcg_5, ndcg_10])\n",
        "\n",
        "    # Report the model's performance on the test set\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"nDCG@3: {ndcg_3}\")\n",
        "    print(f\"nDCG@5: {ndcg_5}\")\n",
        "    print(f\"nDCG@10: {ndcg_10}\")\n",
        "    print(\"-----------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKewQTqDXyyw",
        "outputId": "5bf4fcaa-6c6b-4a3b-a661-2170720f7c55"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.552402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 25637\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 136\n",
            "Fold 1:\n",
            "nDCG@3: 0.4564571300800643\n",
            "nDCG@5: 0.4632890672260867\n",
            "nDCG@10: 0.48286731451235976\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.511309 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25623\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 136\n",
            "Fold 2:\n",
            "nDCG@3: 0.4538895365009714\n",
            "nDCG@5: 0.4573292117374164\n",
            "nDCG@10: 0.4767546810011047\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.440339 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25659\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 136\n",
            "Fold 3:\n",
            "nDCG@3: 0.4490681494620125\n",
            "nDCG@5: 0.4583480538865081\n",
            "nDCG@10: 0.47589507831078093\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.598231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25631\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 136\n",
            "Fold 4:\n",
            "nDCG@3: 0.461178820507814\n",
            "nDCG@5: 0.4663860127875315\n",
            "nDCG@10: 0.487724614983737\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.436681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25501\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 136\n",
            "Fold 5:\n",
            "nDCG@3: 0.46963442883961365\n",
            "nDCG@5: 0.4714315145908388\n",
            "nDCG@10: 0.49035928048966515\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the values for all the folders\n",
        "for fold in range(5):\n",
        "  print(f\"Fold {fold + 1}:\")\n",
        "  print(f\"nDCG@3: {ndcg_values[fold][0]}\")\n",
        "  print(f\"nDCG@5: {ndcg_values[fold][1]}\")\n",
        "  print(f\"nDCG@10: {ndcg_values[fold][2]}\")\n",
        "  print(\"-----------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGtR8itbb8XB",
        "outputId": "5d827e1c-1f0d-4318-a2e6-47bb6519d35e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "nDCG@3: 0.4564571300800643\n",
            "nDCG@5: 0.4632890672260867\n",
            "nDCG@10: 0.48286731451235976\n",
            "-----------------------------------------\n",
            "Fold 2:\n",
            "nDCG@3: 0.4538895365009714\n",
            "nDCG@5: 0.4573292117374164\n",
            "nDCG@10: 0.4767546810011047\n",
            "-----------------------------------------\n",
            "Fold 3:\n",
            "nDCG@3: 0.4490681494620125\n",
            "nDCG@5: 0.4583480538865081\n",
            "nDCG@10: 0.47589507831078093\n",
            "-----------------------------------------\n",
            "Fold 4:\n",
            "nDCG@3: 0.461178820507814\n",
            "nDCG@5: 0.4663860127875315\n",
            "nDCG@10: 0.487724614983737\n",
            "-----------------------------------------\n",
            "Fold 5:\n",
            "nDCG@3: 0.46963442883961365\n",
            "nDCG@5: 0.4714315145908388\n",
            "nDCG@10: 0.49035928048966515\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 14:\n",
        "LightGBM Model Training:\n",
        "For each of the five provided folds, train a LightGBM model using the lambdarank objective. After training, evaluate and report the models performance on the test set using nDCG@3, nDCG@5 and nDCG@10.\n",
        "\n",
        ">Fold 1:\\\n",
        "nDCG@3: 0.4564571300800643\\\n",
        "nDCG@5: 0.4632890672260867\\\n",
        "nDCG@10: 0.48286731451235976\n",
        "\n",
        ">Fold 2:\\\n",
        "nDCG@3: 0.4538895365009714\\\n",
        "nDCG@5: 0.4573292117374164\\\n",
        "nDCG@10: 0.4767546810011047\n",
        "\n",
        ">Fold 3:\\\n",
        "nDCG@3: 0.4490681494620125\\\n",
        "nDCG@5: 0.4583480538865081\\\n",
        "nDCG@10: 0.47589507831078093\n",
        "\n",
        ">Fold 4:\\\n",
        "nDCG@3: 0.461178820507814\\\n",
        "nDCG@5: 0.4663860127875315\\\n",
        "nDCG@10: 0.487724614983737\n",
        "\n",
        ">Fold 5:\\\n",
        "nDCG@3: 0.46963442883961365\\\n",
        "nDCG@5: 0.4714315145908388\\\n",
        "nDCG@10: 0.49035928048966515\n"
      ],
      "metadata": {
        "id": "geWI7YUhHIEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 15**"
      ],
      "metadata": {
        "id": "sgr94M5lc_jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CHANGED HELPED CODE REMOVED booster_ ------- CHECK????\n",
        "top_5_features=[]\n",
        "# Iterate over each fold\n",
        "for fold, (X_train, y_train, qid_train, group_train, X_test, y_test, qid_test, group_test) in enumerate(data):\n",
        "\n",
        "    # Create a LightGBM dataset for training\n",
        "    train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
        "\n",
        "    # Train the LightGBM model\n",
        "    gbm = lgb.train(params, train_data)\n",
        "    # Get feature importance scores\n",
        "    importance_scores = get_feature_importance(gbm, importance_type='gain')\n",
        "\n",
        "    # Create a list of feature names\n",
        "    feature_names = gbm.feature_name()\n",
        "\n",
        "    # Create a dictionary mapping feature names to importance scores\n",
        "    feature_importance_dict = dict(zip(feature_names, importance_scores))\n",
        "\n",
        "    # Sort the feature importance dictionary by importance score in descending order\n",
        "    sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print the top 5 most important features for the current fold\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    features=[]\n",
        "    for feature, score in sorted_feature_importance[:5]:\n",
        "        print(f\"{feature}: {score}\")\n",
        "        features.append((feature,score))\n",
        "    top_5_features.append(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH9KIIrSdAry",
        "outputId": "cdacabda-8dd7-4106-d3de-d9a8e2131988"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.442188 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25637\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 136\n",
            "Fold 1:\n",
            "Column_133: 23856.702950954437\n",
            "Column_7: 4248.546391487122\n",
            "Column_107: 4135.244449853897\n",
            "Column_54: 4078.463216304779\n",
            "Column_129: 3635.03702378273\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.525960 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25623\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 136\n",
            "Fold 2:\n",
            "Column_133: 23578.90825009346\n",
            "Column_7: 5157.964912414551\n",
            "Column_54: 4386.669756650925\n",
            "Column_107: 4094.0121722221375\n",
            "Column_129: 4035.0706725120544\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.457299 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25659\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 136\n",
            "Fold 3:\n",
            "Column_133: 23218.075441122055\n",
            "Column_54: 4991.3033719062805\n",
            "Column_107: 4226.807395458221\n",
            "Column_129: 4059.7525141239166\n",
            "Column_7: 3691.792320251465\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.465097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25631\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 136\n",
            "Fold 4:\n",
            "Column_133: 23796.899673223495\n",
            "Column_7: 4622.622978448868\n",
            "Column_54: 3883.4817056655884\n",
            "Column_129: 3356.8469800949097\n",
            "Column_128: 3207.5755367279053\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.455548 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25501\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 136\n",
            "Fold 5:\n",
            "Column_133: 23540.94235444069\n",
            "Column_7: 4794.9451723098755\n",
            "Column_54: 4079.608554124832\n",
            "Column_107: 3514.8357515335083\n",
            "Column_129: 3209.0584440231323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the top 5 features and their respective scores for all the 5 folders\n",
        "for fold in range(5):\n",
        "  print(f\"Fold {fold + 1} - Top 5 features :\")\n",
        "  print(top_5_features[fold])\n",
        "  print(\"-----------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1BnwF3OeKxR",
        "outputId": "023ee964-aba5-404d-ed70-7bf3c22a2534"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - Top 5 features :\n",
            "[('Column_133', 23856.702950954437), ('Column_7', 4248.546391487122), ('Column_107', 4135.244449853897), ('Column_54', 4078.463216304779), ('Column_129', 3635.03702378273)]\n",
            "-----------------------------------------\n",
            "Fold 2 - Top 5 features :\n",
            "[('Column_133', 23578.90825009346), ('Column_7', 5157.964912414551), ('Column_54', 4386.669756650925), ('Column_107', 4094.0121722221375), ('Column_129', 4035.0706725120544)]\n",
            "-----------------------------------------\n",
            "Fold 3 - Top 5 features :\n",
            "[('Column_133', 23218.075441122055), ('Column_54', 4991.3033719062805), ('Column_107', 4226.807395458221), ('Column_129', 4059.7525141239166), ('Column_7', 3691.792320251465)]\n",
            "-----------------------------------------\n",
            "Fold 4 - Top 5 features :\n",
            "[('Column_133', 23796.899673223495), ('Column_7', 4622.622978448868), ('Column_54', 3883.4817056655884), ('Column_129', 3356.8469800949097), ('Column_128', 3207.5755367279053)]\n",
            "-----------------------------------------\n",
            "Fold 5 - Top 5 features :\n",
            "[('Column_133', 23540.94235444069), ('Column_7', 4794.9451723098755), ('Column_54', 4079.608554124832), ('Column_107', 3514.8357515335083), ('Column_129', 3209.0584440231323)]\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 15:\n",
        "Result Analysis and Interpretation:\n",
        "For each of the five provided folds, list top 5 most important features of the model based on the importance score. Please use model.booster .feature importance(importance type=gain) as demonstrated here for retrieving importance score per feature. You can also find helper code in the provided notebook.\n",
        "\n",
        "> Below are the top 5 features and their respective scores:\n",
        "\n",
        ">Fold 1 - Top 5 features :\\\n",
        "[('Column_133', 23856.702950954437),\\\n",
        "('Column_7', 4248.546391487122),\\\n",
        "('Column_107', 4135.244449853897),\\\n",
        "('Column_54', 4078.463216304779),\\\n",
        "('Column_129', 3635.03702378273)]\n",
        "\n",
        ">Fold 2 - Top 5 features :\\\n",
        "[('Column_133', 23578.90825009346),\\\n",
        "('Column_7', 5157.964912414551),\\\n",
        "('Column_54', 4386.669756650925),\\\n",
        "('Column_107', 4094.0121722221375),\\\n",
        "('Column_129', 4035.0706725120544)]\n",
        "\n",
        ">Fold 3 - Top 5 features :\\\n",
        "[('Column_133', 23218.075441122055),\\\n",
        "('Column_54', 4991.3033719062805),\\\n",
        "('Column_107', 4226.807395458221),\\\n",
        "('Column_129', 4059.7525141239166),\\\n",
        "('Column_7', 3691.792320251465)]\n",
        "\n",
        ">Fold 4 - Top 5 features :\\\n",
        "[('Column_133', 23796.899673223495),\\\n",
        "('Column_7', 4622.622978448868),\\\n",
        "('Column_54', 3883.4817056655884),\\\n",
        "('Column_129', 3356.8469800949097),\\\n",
        "('Column_128', 3207.5755367279053)]\n",
        "\n",
        ">Fold 5 - Top 5 features :\\\n",
        "[('Column_133', 23540.94235444069),\\\n",
        "('Column_7', 4794.9451723098755),\\\n",
        "('Column_54', 4079.608554124832),\\\n",
        "('Column_107', 3514.8357515335083),\\\n",
        "('Column_129', 3209.0584440231323)]\n"
      ],
      "metadata": {
        "id": "TV5APMb1JDr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 16**"
      ],
      "metadata": {
        "id": "d77yczWXlIoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the top 20 features and then finding the ndcg values for the reduced dataset\n",
        "ndcg_values = []\n",
        "# Iterate over each fold\n",
        "for fold, (X_train, y_train, qid_train, group_train, X_test, y_test, qid_test, group_test) in enumerate(data):\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
        "    gbm = lgb.train(params, train_data)\n",
        "    importance_scores = gbm.feature_importance(importance_type='gain')\n",
        "\n",
        "    # Extract the top 20 most important features\n",
        "    top_20_features = np.argsort(importance_scores)[-20:][::-1]\n",
        "\n",
        "    remaining_feature_indices = sorted(set(range(X_train.shape[1])) - set(top_20_features))\n",
        "    X_train_reduced = X_train[:, remaining_feature_indices]\n",
        "    X_test_reduced = X_test[:, remaining_feature_indices]\n",
        "\n",
        "    # Remove the top 20 most important features from the dataset\n",
        "\n",
        "    train_data_reduced = lgb.Dataset(X_train_reduced, label=y_train, group=group_train)\n",
        "    gbm_reduced = lgb.train(params, train_data_reduced)\n",
        "\n",
        "    # Evaluate the performance of the new model on the test set using nDCG\n",
        "    ndcg_3 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=3)\n",
        "    ndcg_5 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=5)\n",
        "    ndcg_10 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=10)\n",
        "\n",
        "    ndcg_values.append([ndcg_3, ndcg_5, ndcg_10])\n",
        "\n",
        "    # Report the model's performance on the test set\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"nDCG@3: {ndcg_3}\")\n",
        "    print(f\"nDCG@5: {ndcg_5}\")\n",
        "    print(f\"nDCG@10: {ndcg_10}\")\n",
        "    print(\"-----------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQPN457WlLjF",
        "outputId": "4c780d85-15f8-4816-f372-a74145da3782"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.573596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25637\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519905 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21582\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 116\n",
            "Fold 1:\n",
            "nDCG@3: 0.37967488460229254\n",
            "nDCG@5: 0.3850299691938894\n",
            "nDCG@10: 0.4083636029390886\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.776973 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25623\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.461926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21551\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 116\n",
            "Fold 2:\n",
            "nDCG@3: 0.3739449461043477\n",
            "nDCG@5: 0.3819536013454118\n",
            "nDCG@10: 0.4045026694861529\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.424079 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25659\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.570663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21720\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 116\n",
            "Fold 3:\n",
            "nDCG@3: 0.3823833692306899\n",
            "nDCG@5: 0.3899961152757789\n",
            "nDCG@10: 0.4116363812695088\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.639413 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25631\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398006 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21670\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 116\n",
            "Fold 4:\n",
            "nDCG@3: 0.381976845689231\n",
            "nDCG@5: 0.39281004672399866\n",
            "nDCG@10: 0.4121071637228934\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.613640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25501\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.407307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21348\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 116\n",
            "Fold 5:\n",
            "nDCG@3: 0.38428336621785103\n",
            "nDCG@5: 0.39216767580543455\n",
            "nDCG@10: 0.4166871494621703\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the values after removing the top 20 features and then finding the ndcg values for the reduced dataset\n",
        "for fold in range(5):\n",
        "  print(f\"Fold {fold + 1}:\")\n",
        "  print(f\"nDCG@3: {ndcg_values[fold][0]}\")\n",
        "  print(f\"nDCG@5: {ndcg_values[fold][1]}\")\n",
        "  print(f\"nDCG@10: {ndcg_values[fold][2]}\")\n",
        "  print(\"-----------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXUwani3xftt",
        "outputId": "6b743a95-b9ac-4c50-c938-fc480df763d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "nDCG@3: 0.37967488460229254\n",
            "nDCG@5: 0.3850299691938894\n",
            "nDCG@10: 0.4083636029390886\n",
            "-----------------------------------------\n",
            "Fold 2:\n",
            "nDCG@3: 0.3739449461043477\n",
            "nDCG@5: 0.3819536013454118\n",
            "nDCG@10: 0.4045026694861529\n",
            "-----------------------------------------\n",
            "Fold 3:\n",
            "nDCG@3: 0.3823833692306899\n",
            "nDCG@5: 0.3899961152757789\n",
            "nDCG@10: 0.4116363812695088\n",
            "-----------------------------------------\n",
            "Fold 4:\n",
            "nDCG@3: 0.381976845689231\n",
            "nDCG@5: 0.39281004672399866\n",
            "nDCG@10: 0.4121071637228934\n",
            "-----------------------------------------\n",
            "Fold 5:\n",
            "nDCG@3: 0.38428336621785103\n",
            "nDCG@5: 0.39216767580543455\n",
            "nDCG@10: 0.4166871494621703\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the bottom 60 features and then finding the ndcg values for the reduced dataset\n",
        "ndcg_values = []\n",
        "# Iterate over each fold\n",
        "for fold, (X_train, y_train, qid_train, group_train, X_test, y_test, qid_test, group_test) in enumerate(data):\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
        "    gbm = lgb.train(params, train_data)\n",
        "    importance_scores = gbm.feature_importance(importance_type='gain')\n",
        "\n",
        "    bottom_60_features = np.argsort(importance_scores)[:60]\n",
        "\n",
        "    remaining_feature_indices = sorted(set(range(X_train.shape[1])) - set(bottom_60_features))\n",
        "    X_train_reduced = X_train[:, remaining_feature_indices]\n",
        "    X_test_reduced = X_test[:, remaining_feature_indices]\n",
        "\n",
        "   # Remove the bottom 60 features\n",
        "\n",
        "    train_data_reduced = lgb.Dataset(X_train_reduced, label=y_train, group=group_train)\n",
        "    gbm_reduced = lgb.train(params, train_data_reduced)\n",
        "\n",
        "    # Evaluate the performance of the new model on the test set using nDCG\n",
        "    ndcg_3 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=3)\n",
        "    ndcg_5 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=5)\n",
        "    ndcg_10 = compute_ndcg_all(gbm_reduced,X_test_reduced, y_test, qid_test, k=10)\n",
        "\n",
        "    ndcg_values.append([ndcg_3, ndcg_5, ndcg_10])\n",
        "\n",
        "    # Report the model's performance on the test set\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"nDCG@3: {ndcg_3}\")\n",
        "    print(f\"nDCG@5: {ndcg_5}\")\n",
        "    print(f\"nDCG@10: {ndcg_10}\")\n",
        "    print(\"-----------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvJjiz3Z3tQy",
        "outputId": "6a007678-5833-4c33-82a0-2511e934b52e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.455896 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25637\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.225748 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 16271\n",
            "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 76\n",
            "Fold 1:\n",
            "nDCG@3: 0.4542530326427776\n",
            "nDCG@5: 0.46265744453383695\n",
            "nDCG@10: 0.4819713060930259\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.975597 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25623\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.970334 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16780\n",
            "[LightGBM] [Info] Number of data points in the train set: 716683, number of used features: 76\n",
            "Fold 2:\n",
            "nDCG@3: 0.457290225801309\n",
            "nDCG@5: 0.4602669061430629\n",
            "nDCG@10: 0.4772534003341443\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.589331 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25659\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.222764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 17029\n",
            "[LightGBM] [Info] Number of data points in the train set: 719111, number of used features: 76\n",
            "Fold 3:\n",
            "nDCG@3: 0.4497901754692966\n",
            "nDCG@5: 0.4586395637756899\n",
            "nDCG@10: 0.4774361560299901\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.452153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25631\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.286811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 16794\n",
            "[LightGBM] [Info] Number of data points in the train set: 718768, number of used features: 76\n",
            "Fold 4:\n",
            "nDCG@3: 0.46063528567047524\n",
            "nDCG@5: 0.46734032124732483\n",
            "nDCG@10: 0.48888147783549574\n",
            "-----------------------------------------\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 25501\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 136\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.250371 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 16338\n",
            "[LightGBM] [Info] Number of data points in the train set: 722602, number of used features: 76\n",
            "Fold 5:\n",
            "nDCG@3: 0.470186124814149\n",
            "nDCG@5: 0.4733522942533459\n",
            "nDCG@10: 0.4908165844880891\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the values after removing the bottom 60 features and then finding the ndcg values for the reduced dataset\n",
        "for fold in range(5):\n",
        "  print(f\"Fold {fold + 1}:\")\n",
        "  print(f\"nDCG@3: {ndcg_values[fold][0]}\")\n",
        "  print(f\"nDCG@5: {ndcg_values[fold][1]}\")\n",
        "  print(f\"nDCG@10: {ndcg_values[fold][2]}\")\n",
        "  print(\"-----------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma-BLZkg33ag",
        "outputId": "b142753b-2f47-4888-f187-f2bb9dac9f8b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "nDCG@3: 0.4542530326427776\n",
            "nDCG@5: 0.46265744453383695\n",
            "nDCG@10: 0.4819713060930259\n",
            "-----------------------------------------\n",
            "Fold 2:\n",
            "nDCG@3: 0.457290225801309\n",
            "nDCG@5: 0.4602669061430629\n",
            "nDCG@10: 0.4772534003341443\n",
            "-----------------------------------------\n",
            "Fold 3:\n",
            "nDCG@3: 0.4497901754692966\n",
            "nDCG@5: 0.4586395637756899\n",
            "nDCG@10: 0.4774361560299901\n",
            "-----------------------------------------\n",
            "Fold 4:\n",
            "nDCG@3: 0.46063528567047524\n",
            "nDCG@5: 0.46734032124732483\n",
            "nDCG@10: 0.48888147783549574\n",
            "-----------------------------------------\n",
            "Fold 5:\n",
            "nDCG@3: 0.470186124814149\n",
            "nDCG@5: 0.4733522942533459\n",
            "nDCG@10: 0.4908165844880891\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 16:\n",
        "\n",
        "Experiments with Subset of Features:\n",
        "For each of the five provided folds:\n",
        "\n",
        "Remove the top 20 most important features according to the computed importance score in the question 15. Then train a new LightGBM model on the resulted 116 dimensional query- url data. Evaluate the performance of this new model on the test set using nDCG. Does the outcome align with your expectations? If not, please share your hypothesis regarding the potential reasons for this discrepancy.\n",
        "\n",
        ">Fold 1:\\\n",
        "nDCG@3: 0.37967488460229254\\\n",
        "nDCG@5: 0.3850299691938894\\\n",
        "nDCG@10: 0.4083636029390886\n",
        "\n",
        ">Fold 2:\\\n",
        "nDCG@3: 0.3739449461043477\\\n",
        "nDCG@5: 0.3819536013454118\\\n",
        "nDCG@10: 0.4045026694861529\n",
        "\n",
        ">Fold 3:\\\n",
        "nDCG@3: 0.3823833692306899\\\n",
        "nDCG@5: 0.3899961152757789\\\n",
        "nDCG@10: 0.4116363812695088\n",
        "\n",
        ">Fold 4:\\\n",
        "nDCG@3: 0.381976845689231\\\n",
        "nDCG@5: 0.39281004672399866\\\n",
        "nDCG@10: 0.4121071637228934\n",
        "\n",
        ">Fold 5:\\\n",
        "nDCG@3: 0.38428336621785103\\\n",
        "nDCG@5: 0.39216767580543455\\\n",
        "nDCG@10: 0.4166871494621703\n",
        "\n",
        "> Yes the output aligns with the expected output. If we remove the top 20 features, we expect the performance to drop. This is why we observe that for each folder, the performance decreases drastically since we removed the important features.\n",
        "\n",
        "Remove the 60 least important features according to the computed importance score in the question 15. Then train a new LightGBM model on the resulted 76 dimensional query-url data. Evaluate the performance of this new model on the test set using nDCG. Does the outcome align with your expectations? If not, please share your hypothesis regarding the potential reasons for this discrepancy.\n",
        "\n",
        ">Fold 1:\\\n",
        "nDCG@3: 0.4542530326427776\\\n",
        "nDCG@5: 0.46265744453383695\\\n",
        "nDCG@10: 0.4819713060930259\n",
        "\n",
        ">Fold 2:\\\n",
        "nDCG@3: 0.457290225801309\\\n",
        "nDCG@5: 0.4602669061430629\\\n",
        "nDCG@10: 0.4772534003341443\n",
        "\n",
        ">Fold 3:\\\n",
        "nDCG@3: 0.4497901754692966\\\n",
        "nDCG@5: 0.4586395637756899\\\n",
        "nDCG@10: 0.4774361560299901\n",
        "\n",
        ">Fold 4:\\\n",
        "nDCG@3: 0.46063528567047524\\\n",
        "nDCG@5: 0.46734032124732483\\\n",
        "nDCG@10: 0.48888147783549574\n",
        "\n",
        ">Fold 5:\\\n",
        "nDCG@3: 0.470186124814149\\\n",
        "nDCG@5: 0.4733522942533459\\\n",
        "nDCG@10: 0.4908165844880891\n",
        "\n",
        "\n",
        "> Yes the output aligns with the expected output. If we remove the bottom 60 features, we expect the performance to not drop drastically. This is because these features do not contribute majorly to the performance. This is why we observe that for each folder, the performance does not decrease much since we removed the least important features."
      ],
      "metadata": {
        "id": "vAxh86zyU-ou"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}